# src/metrics.py
import os
import numpy as np
import matplotlib.pyplot as plt
import evaluate
from transformers import PreTrainedTokenizerBase

# HF evaluateì˜ rouge metric
rouge_metric = evaluate.load("rouge")


def build_compute_metrics(tokenizer: PreTrainedTokenizerBase):
    """
    Seq2SeqTrainerìš© metric í•¨ìˆ˜
    â†’ ROUGE-1 / ROUGE-2 / ROUGE-Lë§Œ ê³„ì‚°
    """

    def compute_metrics(eval_pred):
        preds, labels = eval_pred

        if isinstance(preds, tuple):
            preds = preds[0]

        # -100 â†’ pad_token_id ë¡œ ë˜ëŒë ¤ì„œ ë””ì½”ë”©
        labels_proc = np.where(labels != -100, labels, tokenizer.pad_token_id)

        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)
        decoded_labels = tokenizer.batch_decode(labels_proc, skip_special_tokens=True)

        decoded_preds = [p.strip() for p in decoded_preds]
        decoded_labels = [l.strip() for l in decoded_labels]

        rouge_result = rouge_metric.compute(
            predictions=decoded_preds,
            references=decoded_labels,
            use_stemmer=True,
        )

        # ğŸ”§ evaluate ë²„ì „ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ì´ ë‹¬ë¼ì ¸ë„ ë‹¤ ì²˜ë¦¬ë˜ë„ë¡ í—¬í¼ í•¨ìˆ˜ ì •ì˜
        def get_f1(score):
            # ì˜ˆì „: Score ê°ì²´( score.mid.fmeasure )
            if hasattr(score, "mid"):
                return score.mid.fmeasure
            # dict í˜•íƒœ: {"fmeasure": ..., "precision": ..., ...} ë“±
            if isinstance(score, dict):
                if "fmeasure" in score:
                    return score["fmeasure"]
                if "f" in score:  # í˜¹ì‹œ ì´ë ‡ê²Œ ì˜¤ëŠ” ê²½ìš°
                    return score["f"]
            # ì´ë¯¸ float / numpy.float64 ì¸ ê²½ìš°
            return float(score)

        rouge1 = get_f1(rouge_result["rouge1"])
        rouge2 = get_f1(rouge_result["rouge2"])
        rougel = get_f1(rouge_result["rougeL"])

        return {
            "rouge1": rouge1,
            "rouge2": rouge2,
            "rougeL": rougel,
        }

    return compute_metrics


def plot_metrics_from_history(trainer, log_dir: str):
    """
    trainer.state.log_historyì—ì„œ eval_* ë¡œê·¸ ë½‘ì•„ì„œ
    ROUGE-1 / 2 / L ê·¸ë˜í”„ ì €ì¥
    """
    history = trainer.state.log_history
    epochs = []
    r1_list, r2_list, rl_list = [], [], []

    for log in history:
        if "eval_rouge1" in log:
            ep = log.get("epoch")
            if ep is None:
                continue
            epochs.append(ep)
            r1_list.append(log.get("eval_rouge1", float("nan")))
            r2_list.append(log.get("eval_rouge2", float("nan")))
            rl_list.append(log.get("eval_rougeL", float("nan")))

    if not epochs:
        print("[WARN] eval ë¡œê·¸ê°€ ì—†ì–´ ê·¸ë˜í”„ ëª» ë§Œë“¦.")
        return

    plt.figure(figsize=(8, 6))
    plt.plot(epochs, r1_list, marker="o", label="ROUGE-1")
    plt.plot(epochs, r2_list, marker="o", label="ROUGE-2")
    plt.plot(epochs, rl_list, marker="o", label="ROUGE-L")
    plt.xlabel("Epoch")
    plt.ylabel("Score")
    plt.title("Validation ROUGE scores per Epoch")
    plt.grid(True)
    plt.legend()

    os.makedirs(log_dir, exist_ok=True)
    out_path = os.path.join(log_dir, "val_metrics.png")
    plt.tight_layout()
    plt.savefig(out_path)
    plt.close()
    print(f"[INFO] Validation metric plot saved to {out_path}")

def plot_loss_from_history(trainer, log_dir: str):
    """
    Trainer log_historyì—ì„œ train_loss / eval_lossë¥¼ ì¶”ì¶œí•˜ì—¬ PNGë¡œ ì €ì¥
    """
    history = trainer.state.log_history

    epochs = []
    train_losses = []
    val_losses = []

    cur_train_loss = None

    for log in history:
        # train ì†ì‹¤
        if "loss" in log and "epoch" in log:
            cur_train_loss = log["loss"]
            # ê°™ì€ epoch ì•ˆì—ì„œ ì—¬ëŸ¬ stepì´ ìˆì„ ìˆ˜ ìˆìŒ â†’ ê°€ì¥ ë§ˆì§€ë§‰ loss ì‚¬ìš©
            train_losses.append((log["epoch"], cur_train_loss))

        # validation ì†ì‹¤
        if "eval_loss" in log and "epoch" in log:
            val_losses.append((log["epoch"], log["eval_loss"]))

    if not train_losses and not val_losses:
        print("[WARN] loss ë¡œê·¸ê°€ ì—†ì–´ ê·¸ë˜í”„ ìƒì„± ë¶ˆê°€.")
        return

    # epoch / loss ë¶„ë¦¬
    train_epochs = [ep for ep, _ in train_losses]
    train_loss_values = [ls for _, ls in train_losses]

    val_epochs = [ep for ep, _ in val_losses]
    val_loss_values = [ls for _, ls in val_losses]

    # ------------ PLOT ------------
    plt.figure(figsize=(8, 6))
    if train_losses:
        plt.plot(train_epochs, train_loss_values, marker="o", label="Train Loss")
    if val_losses:
        plt.plot(val_epochs, val_loss_values, marker="o", label="Validation Loss")

    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Train / Validation Loss per Epoch")
    plt.legend()
    plt.grid(True)

    out_path = os.path.join(log_dir, "loss_curve.png")
    plt.tight_layout()
    plt.savefig(out_path)
    plt.close()

    print(f"[INFO] Loss plot saved to {out_path}")
