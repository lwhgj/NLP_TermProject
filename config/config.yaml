model:
  name: "gogamza/kobart-base-v2"

data:
  train_csv: "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/data/train_kobart.csv"
  test_csv:  "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/data/test_data/test_kobart.csv"
  val_ratio: 0.1

max_length:
  input_max_len: 1024      # í•™ìŠµ/í† í¬ë‚˜ì´ì§•ìš© ì…ë ¥ ìµœëŒ€ ê¸¸ì´
  target_max_len: 512     # í•™ìŠµìš© íƒ€ê²Ÿ ìµœëŒ€ ê¸¸ì´

training:
  num_train_epochs: 10
  train_batch_size: 8
  learning_rate: 0.00003
  weight_decay: 0.01
  warmup_ratio: 0.1

logging:
  log_root: "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/log"

paths:
  # eval_kobart.py / infer_kobart.py ì—ì„œ ê³µí†µìœ¼ë¡œ ì“¸ best model ê²½ë¡œ
  model_dir: "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/log/2025-11-29_23-51-36/best_model"

  infer_pdf: "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/data/test_data/test_input/2022_LGí™”í•™_preprocessing.txt"
  # eval_kobart.py ì—ì„œ ì“¸ test_csv
  test_csv:  "C:/Users/inwoo/PycharmProjects/NLP/NLP_TermProject/data/test_data/test_kobart.csv"

# ğŸ”¥ ì—¬ê¸°ë¶€í„° ìƒˆë¡œ ì¶”ê°€: ì‹¤ì œ "ìƒì„±"ì— ì“¸ ì„¤ì •
generate:
  max_input_len: 768      # infer ì‹œ ì…ë ¥ ìµœëŒ€ ê¸¸ì´ (ë³´í†µ max_length.input_max_len ê³¼ ë§ì¶¤)
  max_new_tokens: 303     # âœ… ìƒˆë¡œ ìƒì„±í•  í† í° ìˆ˜ ìƒí•œ (ìš”ì•½ì˜ ìµœëŒ€ ê¸¸ì´)
  min_length: 100          # âœ… ìš”ì•½ ìµœì†Œ ê¸¸ì´ (ë„ˆë¬´ ì§§ì€ ë‹µ ë°©ì§€)
  num_beams: 4            # beam search ë¹” ìˆ˜
  length_penalty: 1.3    # âœ… 1.0ë³´ë‹¤ í¬ë©´ ì§§ê²Œ ìš”ì•½í•˜ëŠ” ìª½ì„ ì„ í˜¸

seed: 42
